<!DOCTYPE html>
<html>
<head>
  <title>Speech Recognition</title>
</head>
<body>
  <h1>Speech Recognition Example</h1>
  <button id="startButton">Start</button>
  <p id="status"></p>
  <audio id="audio" controls></audio>

  <script>
    const startButton = document.getElementById("startButton");
    const status = document.getElementById("status");
    const audio = document.getElementById("audio");

    const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition || window.mozSpeechRecognition || window.msSpeechRecognition)();
    recognition.lang = 'en-US';

    let chunks = [];

    startButton.addEventListener('click', () => {
      chunks = [];
      recognition.start();
      status.textContent = "Listening...";
    });

    recognition.onaudiostart = () => {
      status.textContent = "Recording...";
    };

    recognition.onaudioend = () => {
      status.textContent = "Processing...";
      recognition.stop();
    };

    recognition.onnomatch = () => {
      status.textContent = "No speech recognized";
    };

    recognition.onerror = (event) => {
      console.error(event.error);
      status.textContent = "Error: " + event.error;
    };

    recognition.onresult = (event) => {
      const result = event.results[0][0].transcript;
      status.textContent = "Finished: " + result;
      audio.controls = true;

      const audioBlob = new Blob(chunks, { type: 'audio/webm' });
      const audioUrl = URL.createObjectURL(audioBlob);
      audio.src = audioUrl;
    };

    recognition.ondataavailable = (event) => {
      chunks.push(event.data);
    };
  </script>
</body>
</html>
